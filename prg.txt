//5
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(
    iris.data, iris.target, test_size=0.3, random_state=42)

model = DecisionTreeClassifier(criterion='entropy', max_depth=3).fit(X_train, y_train)
print("Accuracy:", accuracy_score(y_test, model.predict(X_test)))

plot_tree(model, feature_names=iris.feature_names, class_names=iris.target_names, filled=True)
plt.show()

print(export_text(model, feature_names=iris.feature_names))

===========================================================
//6
from sklearn import datasets
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

iris = datasets.load_iris()
X = StandardScaler().fit_transform(iris.data)

kmeans = KMeans(n_clusters=3, random_state=42).fit(X)

labels = kmeans.labels_
centroids = kmeans.cluster_centers_

plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')
plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=200, marker='X')
plt.show()

print("Centers:\n", centroids)
print("True:", iris.target[:10])
print("Pred:", labels[:10])

===========================================================
//7
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt

digits = load_digits()
X, y = digits.data, digits.target
print("Data:", X.shape, "Labels:", y.shape)

plt.figure(figsize=(8,4))
for i in range(8):
    plt.subplot(2,4,i+1)
    plt.imshow(X[i].reshape(8,8), cmap='gray')
    plt.title(f'{y[i]}')
plt.show()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

sc = StandardScaler()
X_train, X_test = sc.fit_transform(X_train), sc.transform(X_test)

model = SVC(kernel='rbf', gamma=0.05, C=10).fit(X_train, y_train)
pred = model.predict(X_test)

print(confusion_matrix(y_test, pred))
print(classification_report(y_test, pred))
print("Accuracy:", accuracy_score(y_test, pred))

plt.figure(figsize=(8,4))
for i in range(8):
    plt.subplot(2,4,i+1)
    plt.imshow(X_test[i].reshape(8,8), cmap='gray')
    plt.title(f"P:{pred[i]} T:{y_test[i]}")
plt.show()

===========================================================
//8
from sklearn.datasets import load_digits
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import numpy as np

digits = load_digits()
X, y = digits.data, digits.target
print("Dataset:", X.shape)

X = StandardScaler().fit_transform(X)

pca = PCA(30)
X_pca = pca.fit_transform(X)
print("Reduced:", X_pca.shape)

plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')
plt.xlabel("Components"); plt.ylabel("Cumulative Variance")
plt.title("Explained Variance"); plt.show()

plt.scatter(X_pca[:,0], X_pca[:,1], c=y, cmap='tab10', s=10)
plt.xlabel("PC1"); plt.ylabel("PC2")
plt.title("Digits PCA (First 2 Components)"); plt.colorbar(); plt.show()
